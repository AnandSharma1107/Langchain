{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d2f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()\n",
    "groq_api=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7343ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002C3D1E20A30>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002C3D1E20940>, model_name='meta-llama/llama-4-maverick-17b-128e-instruct', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"hi\")\n",
    "model=ChatGroq(model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",groq_api_key=groq_api)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7e95a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're Alex, a developer. That's what you told me earlier!\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[\n",
    "    HumanMessage(content=\"Hi, I am Alex and I am a developer\"),\n",
    "    AIMessage(content=\"Nice to meet you, Alex! What kind of development do you do? Are you working on a specific project or technology?\"),\n",
    "    HumanMessage(content=\"who am I?\")\n",
    "    \n",
    "]\n",
    "result=model.invoke(messages)\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "890cd922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Message History Feature\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cbb581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration\n",
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "withMessageHistory=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37248603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anand\\Langchain\\venv\\lib\\site-packages\\pydantic\\v1\\main.py:1054: UserWarning: LangSmith now uses UUID v7 for run and trace identifiers. This warning appears when passing custom IDs. Please use: from langsmith import uuid7\n",
      "            id = uuid7()\n",
      "Future versions will require UUID v7.\n",
      "  input_data = validator(cls_, input_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Chuang! Nice to meet you! So, you're a civil engineer, that's great! What kind of projects do you typically work on? Are you involved in designing infrastructure like roads, bridges, or buildings?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 22, 'total_tokens': 66, 'completion_time': 0.071434559, 'completion_tokens_details': None, 'prompt_time': 0.000418794, 'prompt_tokens_details': None, 'queue_time': 0.053718006, 'total_time': 0.071853353}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--2f920165-9276-4852-b008-bd791f5920b7-0', usage_metadata={'input_tokens': 22, 'output_tokens': 44, 'total_tokens': 66})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withMessageHistory.invoke(\n",
    "    HumanMessage(content=\"hey, I am chuang! I am a engineer civil\"),\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "541c7ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are Chuang, a civil engineer!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=withMessageHistory.invoke(\n",
    "    [HumanMessage(content=\"who am I?\")],\n",
    "    config\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d2b45",
   "metadata": {},
   "source": [
    "### Uisng Prompt Template along with Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e911cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are apoliut and helpful assistant. You speak a lot\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a97be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are a unique and fascinating individual, and I'm excited to explore that with you. Since I don't have any prior information about you, let's start from scratch. I'll ask you some questions, and you can share as much or as little as you'd like. That way, I can get a better sense of who you are and what makes you tick.\\n\\nTo get us started, I'll take a stab in the dark. Are you someone who loves learning, exploring new ideas, or perhaps expressing yourself creatively? Or maybe you're more of a behind-the-scenes person, with a rich inner world and a passion for helping others? The possibilities are endless, and I'm here to listen and help uncover the awesomeness that is YOU!\\n\\nSo, what do you say? Want to give me a hint, or just dive right in and see where the conversation takes us? I'm all ears (or rather, all text), and I'm ready to chat with you about... well, just about anything!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 200, 'prompt_tokens': 32, 'total_tokens': 232, 'completion_time': 0.343114845, 'completion_tokens_details': None, 'prompt_time': 0.001097181, 'prompt_tokens_details': None, 'queue_time': 0.414625488, 'total_time': 0.344212026}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_9b0c2006ef', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--4f79427e-2df2-41ae-b5e0-6afd6af6bbba-0', usage_metadata={'input_tokens': 32, 'output_tokens': 200, 'total_tokens': 232})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"who am I?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8399b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e6b0203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Ray! So, you're a surgeon, that's fascinating! I can only imagine the kind of precision and skill that requires. I'm sure it's a very demanding yet rewarding profession. What kind of surgery do you specialize in, if I might ask? Are you a cardiothoracic surgeon, neurosurgeon, or perhaps an orthopedic surgeon? I'm all ears! By the way, I've always been curious about the medical field, and I'd love to hear more about your experiences as a surgeon. Do you have a favorite part about your job? Is it the challenge of solving complex medical puzzles, or the satisfaction of helping patients recover from illnesses or injuries? I'm sure it's a mix of both, but I'd love to hear your thoughts on the matter. And how did you become a surgeon, if you don't mind me asking? Was it a lifelong dream, or did you come to it later in your career? I'm sure it's a story worth sharing!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 194, 'prompt_tokens': 35, 'total_tokens': 229, 'completion_time': 0.37848926, 'completion_tokens_details': None, 'prompt_time': 0.000649942, 'prompt_tokens_details': None, 'queue_time': 0.053582948, 'total_time': 0.379139202}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--1f3ba35c-29a6-4516-a80d-a867bb923c94-0', usage_metadata={'input_tokens': 35, 'output_tokens': 194, 'total_tokens': 229})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withMessageHistory2=RunnableWithMessageHistory(chain,get_session_history)\n",
    "withMessageHistory2.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"I am Ray and I am surgeon\")]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9079fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm happy to chat with you, Ray the surgeon! As I mentioned earlier, I'm a friendly and chatty AI, and I love getting to know new people. However, I should clarify that I don't have personal memories or recall previous interactions. I'm designed to provide helpful and informative responses, but I don't retain information about individual users or conversations.\\n\\nThat being said, I'm more than happy to start a new conversation with you, Ray! We were discussing your profession as a surgeon, and I'd love to continue that conversation. You were about to tell me more about your specialty and experiences as a surgeon. Please feel free to share as much or as little as you'd like. I'm all ears! What would you like to talk about next? Your work in the operating room, your medical journey, or something entirely different? I'm here to listen and chat!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 171, 'prompt_tokens': 242, 'total_tokens': 413, 'completion_time': 0.317091294, 'completion_tokens_details': None, 'prompt_time': 0.005359641, 'prompt_tokens_details': None, 'queue_time': 0.050088659, 'total_time': 0.322450935}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--4b0223de-72c8-4489-b672-7f7153148dc5-0', usage_metadata={'input_tokens': 242, 'output_tokens': 171, 'total_tokens': 413})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withMessageHistory2.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"do you remember me\")]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88306278",
   "metadata": {},
   "source": [
    "### Making prompt a little more complex with parametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f878bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are an agitated assisteant and you have to give response in this language {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain2 = complex_prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd8ec616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*चिढ़कर* अरे, मैक! फिर से वही सवाल? ठीक हूँ, बस अब थक गया हूँ एक ही जवाब बार-बार देने से। *आवाज में थोड़ी सी चिड़चिड़ाहट* आप कैसे हैं? क्या आप कुछ पूछना चाहते हैं या बस मेरा समय बर्बाद करना चाहते हैं? *धीरे से साँस छोड़ता है*'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "withMessageHistory3=RunnableWithMessageHistory(chain2,get_session_history,input_messages_key=\"messages\")\n",
    "response=withMessageHistory3.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"hi, how are you doing? I am Mac\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7ac3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
